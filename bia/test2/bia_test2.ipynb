{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5lVhqaD6COQnKuBh5/huN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RazvanGolan/Faculty-3rd-year/blob/main/bia/test2/bia_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BrMd93M_Xbs",
        "outputId": "ec31c1e9-8f1f-4cdb-f6a6-947ec9b9905e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -625,   -10, -1620])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# exercise 1\n",
        "import torch\n",
        "a = torch.tensor([[4, 5], [-2, 1], [0, 6]])\n",
        "b = torch.tensor([[3, 0, -1], [2, 2, 10]])\n",
        "\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "\n",
        "c = b[0] + a@b\n",
        "x = a[:, 1]\n",
        "f = -c[0]*(x*x)\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 2\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    # Declare a layer with model parameters. Here, we declare two fully\n",
        "    # connected layers\n",
        "    def __init__(self):\n",
        "        # Call the constructor of the `MLP` parent class `nn.Module` to perform\n",
        "        # the necessary initialization. In this way, other function arguments\n",
        "        # can also be specified during class instantiation, such as the model\n",
        "        # parameters\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(32, 512)  # Hidden layer\n",
        "        self.out = nn.Linear(512, 10)  # Output layer\n",
        "\n",
        "    # Define the forward propagation of the model, that is, how to return the\n",
        "    # required model output, based on the input `X`\n",
        "    def forward(self, X):\n",
        "        # Note here we use the nn.ReLU class for the ReLU activation function\n",
        "        return self.out(nn.ReLU()(self.hidden(X)))"
      ],
      "metadata": {
        "id": "er1gPYQHAtPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()"
      ],
      "metadata": {
        "id": "P7T87iiD_5KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize=None):\n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
        "    trans = [transforms.ToTensor()]\n",
        "    if resize:\n",
        "        trans.insert(0, transforms.Resize(resize))\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.CIFAR10(\n",
        "        root=\"../data\", train=True, transform=trans, download=True)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(\n",
        "        root=\"../data\", train=False, transform=trans, download=True)\n",
        "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [7000, 43000],\n",
        "                                                           generator=torch.Generator().manual_seed(42))\n",
        "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=2),\n",
        "            torch.utils.data.DataLoader(mnist_val, batch_size, shuffle=False,\n",
        "                            num_workers=2),\n",
        "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=2))"
      ],
      "metadata": {
        "id": "pg-WjqixBm6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_iter, val_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "lr = 0.01\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImUmFCCbB5mP",
        "outputId": "ca04b04f-d14f-4c3c-e8a3-64940c7eb49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(net, data_iter, loss, device):\n",
        "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
        "    net.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_loss = 0\n",
        "    total_hits = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            total_loss += float(l)\n",
        "            total_hits += sum(net(X).argmax(axis=1).type(y.dtype) == y)\n",
        "            total_samples += y.numel()\n",
        "    return float(total_loss) / len(data_iter), float(total_hits) / total_samples  * 100"
      ],
      "metadata": {
        "id": "EH_6ByCxCtmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(net, train_iter, loss, optimizer, device):\n",
        "    # Set the model to training mode\n",
        "    net.train()\n",
        "    # Sum of training loss, sum of training correct predictions, no. of examples\n",
        "    total_loss = 0\n",
        "    total_hits = 0\n",
        "    total_samples = 0\n",
        "    for X, y in train_iter:\n",
        "        # Compute gradients and update parameters\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_hat = net(X)\n",
        "        l = loss(y_hat, y)\n",
        "        # Using PyTorch built-in optimizer & loss criterion\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(l)\n",
        "        total_hits += sum(y_hat.argmax(axis=1).type(y.dtype) == y)\n",
        "        total_samples += y.numel()\n",
        "    # Return training loss and training accuracy\n",
        "    return float(total_loss) / len(train_iter), float(total_hits) / total_samples  * 100"
      ],
      "metadata": {
        "id": "qsjWJ3VeC6WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, val_iter, test_iter, num_epochs, lr, device):\n",
        "    \"\"\"Train a model.\"\"\"\n",
        "    train_loss_all = []\n",
        "    train_acc_all = []\n",
        "    val_loss_all = []\n",
        "    val_acc_all = []\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "    net.apply(init_weights)\n",
        "    print('Training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_epoch(net, train_iter, loss, optimizer, device)\n",
        "        train_loss_all.append(train_loss)\n",
        "        train_acc_all.append(train_acc)\n",
        "        val_loss, val_acc = evaluate_accuracy(net, val_iter, loss, device)\n",
        "        val_loss_all.append(val_loss)\n",
        "        val_acc_all.append(val_acc)\n",
        "        print(f'Epoch {epoch + 1}, Train loss {train_loss:.2f}, Train accuracy {train_acc:.2f}, Validation loss {val_loss:.2f}, Validation accuracy {val_acc:.2f}')\n",
        "    test_loss, test_acc = evaluate_accuracy(net, test_iter, loss, device)\n",
        "    print(f'Test loss {test_loss:.2f}, Test accuracy {test_acc:.2f}')\n",
        "\n",
        "    return train_loss_all, train_acc_all, val_loss_all, val_acc_all"
      ],
      "metadata": {
        "id": "R2VK7EriC6tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ],
      "metadata": {
        "id": "FdHeMKRcJp2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "train_loss_all, train_acc_all, val_loss_all, val_acc_all = train(net, train_iter, val_iter, test_iter, num_epochs, lr, try_gpu()) #2 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NyJVvox8C8CJ",
        "outputId": "7e32135e-7b72-4384-b7e2-feaf8fffacac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [256]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-201b202fd1a7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loss_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2 min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-7c921ddee245>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, val_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_loss_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_acc_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-935b7590d841>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(net, train_iter, loss, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Using PyTorch built-in optimizer & loss criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [256]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(train_loss_all, val_loss_all):\n",
        "    epochs = range(1, len(train_loss_all) + 1)\n",
        "    plt.plot(epochs, train_loss_all, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss_all, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss(train_loss_all, val_loss_all)"
      ],
      "metadata": {
        "id": "WsFp51VzC-AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy(train_acc_all, val_acc_all):\n",
        "    epochs = range(1, len(train_acc_all) + 1)\n",
        "    plt.plot(epochs, train_acc_all, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc_all, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_accuracy(train_acc_all, val_acc_all)"
      ],
      "metadata": {
        "id": "rOGOLuTEDe1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate_accuracy(net, test_iter)\n",
        "print(f'Test loss {test_loss:.2f}, Test accuracy {test_acc:.2f}')"
      ],
      "metadata": {
        "id": "vUy4aiPuDgvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 3\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize=None):\n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
        "    trans = [transforms.ToTensor()]\n",
        "    if resize:\n",
        "        trans.insert(0, transforms.Resize(resize))\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.CIFAR100(\n",
        "        root=\"../data\", train=True, transform=trans, download=True)\n",
        "    mnist_test = torchvision.datasets.CIFAR100(\n",
        "        root=\"../data\", train=False, transform=trans, download=True)\n",
        "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [6000, 44000],\n",
        "                                                           generator=torch.Generator().manual_seed(42))\n",
        "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=2),\n",
        "            torch.utils.data.DataLoader(mnist_val, batch_size, shuffle=False,\n",
        "                            num_workers=2),\n",
        "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=2))"
      ],
      "metadata": {
        "id": "MlFTCHJWK7z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"The Residual block of ResNet.\"\"\"\n",
        "    def __init__(self, input_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.left_avg = nn.AvgPool2d(kernel_size=2, stride=16)\n",
        "        self.left_conv = nn.Conv2d(input_channels, 32, kernel_size=1)\n",
        "        self.left_batch = nn.BatchNorm2d(32)\n",
        "        self.left_relu = nn.ReLU()\n",
        "\n",
        "        self.middle_conv = nn.Conv2d(input_channels, 32, kernel_size=1, stride=16)\n",
        "        self.middle_batch = nn.BatchNorm2d(32)\n",
        "        self.middle_relu = nn.ReLU()\n",
        "\n",
        "        self.right_conv = nn.Conv2d(input_channels, 64, kernel_size=1)\n",
        "        self.right_first_relu = nn.ReLU()\n",
        "\n",
        "        self.right_conv2 = nn.Conv2d(64, 32, kernel_size=(1, 3), stride = 16)\n",
        "        self.right_relu2 = nn.ReLU()\n",
        "\n",
        "        self.right_conv3 = nn.Conv2d(64, 32, kernel_size=(3, 1), stride = 16)\n",
        "        self.right_relu3 = nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        left = self.left_avg(X)\n",
        "        left = self.left_conv(left)\n",
        "        left = self.left_batch(left)\n",
        "        left = self.left_relu(left)\n",
        "\n",
        "        middle = self.middle_conv(X)\n",
        "        middle = self.middle_batch(middle)\n",
        "        middle = self.middle_relu(middle)\n",
        "\n",
        "        right1 = self.right_conv(X)\n",
        "        right1 = self.right_first_relu(right1)\n",
        "\n",
        "        right2 = self.right_conv2(right1)\n",
        "        right2 = self.right_relu2(right2)\n",
        "\n",
        "        right3 = self.right_conv3(right1)\n",
        "        right3 = self.right_relu3(right3)\n",
        "\n",
        "        out = torch.concat((left, middle, right2, right3), dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "XFDDRnhLLA_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    MLP(3),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(512, 100)\n",
        ")\n",
        "\n",
        "out = MLP(3)(torch.rand((1, 3, 32, 32)))\n",
        "\n",
        "print(out.shape)\n",
        "\n",
        "out = nn.Flatten()(out)\n",
        "\n",
        "print(out.shape)\n",
        "\n",
        "out = nn.Linear(512, 100)(out)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juJOi1soLA87",
        "outputId": "25494622-465f-485d-aea5-3ef63990307a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128, 2, 2])\n",
            "torch.Size([1, 512])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_iter, val_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "lr = 0.05\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "num_epochs = 5\n",
        "train_loss_all, train_acc_all, val_loss_all, val_acc_all = train(net, train_iter, val_iter, test_iter, num_epochs, lr, try_gpu()) #2 min\n",
        "\n",
        "# i got Test loss 4.31, Test accuracy 5.37 better than required"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTl7Lv7MLA6I",
        "outputId": "6a636f4f-118c-436e-c859-0d47adea6049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:05<00:00, 29.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-100-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n",
            "Training on cuda:0\n",
            "Epoch 1, Train loss 4.68, Train accuracy 1.03, Validation loss 4.59, Validation accuracy 1.73\n",
            "Epoch 2, Train loss 4.49, Train accuracy 3.32, Validation loss 4.50, Validation accuracy 3.20\n",
            "Epoch 3, Train loss 4.38, Train accuracy 4.75, Validation loss 4.40, Validation accuracy 4.39\n",
            "Epoch 4, Train loss 4.31, Train accuracy 5.92, Validation loss 4.34, Validation accuracy 4.90\n",
            "Epoch 5, Train loss 4.25, Train accuracy 6.62, Validation loss 4.30, Validation accuracy 5.24\n",
            "Test loss 4.31, Test accuracy 5.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 4\n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "import collections\n",
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "torch.manual_seed(42);\n",
        "\n",
        "def download(url, cache_dir=os.path.join('..', 'data')):\n",
        "    \"\"\"Download a file, return the local filename.\"\"\"\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "        return fname\n",
        "    print(f'Downloading {fname} from {url}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def read_time_machine():\n",
        "    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n",
        "    with open(download('https://s3.amazonaws.com/text-datasets/nietzsche.txt'), 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
        "\n",
        "lines = read_time_machine()\n",
        "print(f'# text lines: {len(lines)}')\n",
        "print(lines[0])\n",
        "print(lines[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4-HvTsoDh6K",
        "outputId": "6c4f06fa-a0ea-436d-bc40-d5d816ca419b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/nietzsche.txt from https://s3.amazonaws.com/text-datasets/nietzsche.txt...\n",
            "# text lines: 9935\n",
            "preface\n",
            "indeed it stands at all for there are scoffers who maintain that it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lines, token='word'):\n",
        "    \"\"\"Split text lines into word or character tokens.\"\"\"\n",
        "    if token == 'word':\n",
        "        return [line.split() for line in lines]\n",
        "    elif token == 'char':\n",
        "        return [list(line) for line in lines]\n",
        "    else:\n",
        "        print('ERROR: unknown token type: ' + token)\n",
        "\n",
        "tokens = tokenize(lines)\n",
        "for i in range(11):\n",
        "    print(tokens[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Uvj82BEhpN",
        "outputId": "a5703500-bf3a-45e2-9c23-f84c3d184c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['preface']\n",
            "[]\n",
            "[]\n",
            "['supposing', 'that', 'truth', 'is', 'a', 'woman', 'what', 'then', 'is', 'there', 'not', 'ground']\n",
            "['for', 'suspecting', 'that', 'all', 'philosophers', 'in', 'so', 'far', 'as', 'they', 'have', 'been']\n",
            "['dogmatists', 'have', 'failed', 'to', 'understand', 'women', 'that', 'the', 'terrible']\n",
            "['seriousness', 'and', 'clumsy', 'importunity', 'with', 'which', 'they', 'have', 'usually', 'paid']\n",
            "['their', 'addresses', 'to', 'truth', 'have', 'been', 'unskilled', 'and', 'unseemly', 'methods', 'for']\n",
            "['winning', 'a', 'woman', 'certainly', 'she', 'has', 'never', 'allowed', 'herself', 'to', 'be', 'won', 'and']\n",
            "['at', 'present', 'every', 'kind', 'of', 'dogma', 'stands', 'with', 'sad', 'and', 'discouraged', 'mien', 'if']\n",
            "['indeed', 'it', 'stands', 'at', 'all', 'for', 'there', 'are', 'scoffers', 'who', 'maintain', 'that', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    \"\"\"Vocabulary for text.\"\"\"\n",
        "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "        # Sort according to frequencies\n",
        "        counter = count_corpus(tokens)\n",
        "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
        "                                   reverse=True)\n",
        "        # The index for the unknown token is 0\n",
        "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "        self.token_to_idx = {token: idx\n",
        "                             for idx, token in enumerate(self.idx_to_token)}\n",
        "        for token, freq in self._token_freqs:\n",
        "            if freq < min_freq:\n",
        "                break\n",
        "            if token not in self.token_to_idx:\n",
        "                self.idx_to_token.append(token)\n",
        "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "    @property\n",
        "    def unk(self):  # Index for the unknown token\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def token_freqs(self):  # Token frequencies\n",
        "        return self._token_freqs\n",
        "\n",
        "def count_corpus(tokens):\n",
        "    \"\"\"Count token frequencies.\"\"\"\n",
        "    # Here `tokens` is a 1D list or 2D list\n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "        # Flatten a list of token lists into a list of tokens\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "    return collections.Counter(tokens)"
      ],
      "metadata": {
        "id": "kT17xVK1Eh4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus_time_machine(max_tokens=-1):\n",
        "    \"\"\"Return token indices and the vocabulary of the time machine dataset.\"\"\"\n",
        "    lines = read_time_machine()\n",
        "    tokens = tokenize(lines, 'char')\n",
        "    vocab = Vocab(tokens)\n",
        "    # Since each text line in the time machine dataset is not necessarily a\n",
        "    # sentence or a paragraph, flatten all the text lines into a single list\n",
        "    corpus = [vocab[token] for line in tokens for token in line]\n",
        "    if max_tokens > 0:\n",
        "        corpus = corpus[:max_tokens]\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus, vocab = load_corpus_time_machine()\n",
        "len(corpus), len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo3Y2e_AEjen",
        "outputId": "642295aa-49e9-4e2e-a378-4085b0258d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570394, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
        "    \"\"\"Generate a mini-batch of subsequences using sequential partitioning.\"\"\"\n",
        "    # Start with a random offset to partition a sequence\n",
        "    offset = random.randint(0, num_steps)\n",
        "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
        "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
        "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
        "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
        "    num_batches = Xs.shape[1] // num_steps\n",
        "    for i in range(0, num_steps * num_batches, num_steps):\n",
        "        X = Xs[:, i: i + num_steps]\n",
        "        Y = Ys[:, i: i + num_steps]\n",
        "        yield X, Y"
      ],
      "metadata": {
        "id": "_WkK8PbFEnGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqDataLoader:\n",
        "    \"\"\"An iterator to load sequence data.\"\"\"\n",
        "    def __init__(self, batch_size, num_steps, max_tokens):\n",
        "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
        "        self.batch_size, self.num_steps = batch_size, num_steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        return seq_data_iter_sequential(self.corpus, self.batch_size, self.num_steps)"
      ],
      "metadata": {
        "id": "hcOXzARoEoWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_time_machine(batch_size, num_steps, max_tokens=10000):\n",
        "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\n",
        "    data_iter = SeqDataLoader(\n",
        "        batch_size, num_steps, max_tokens)\n",
        "    return data_iter, data_iter.vocab"
      ],
      "metadata": {
        "id": "Rf9K-LyFEp-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    \"\"\"The RNN model.\"\"\"\n",
        "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
        "        super(RNNModel, self).__init__(**kwargs)\n",
        "        self.rnn = rnn_layer\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_hiddens = self.rnn.hidden_size\n",
        "        self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
        "\n",
        "    def forward(self, inputs, state):\n",
        "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
        "        X = X.to(torch.float32)\n",
        "        Y, state = self.rnn(X, state)\n",
        "        # The fully connected layer will first change the shape of `Y` to\n",
        "        # (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is\n",
        "        # (`num_steps` * `batch_size`, `vocab_size`).\n",
        "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
        "        return output, state\n",
        "\n",
        "    def begin_state(self, device, batch_size=1):\n",
        "        if not isinstance(self.rnn, nn.LSTM):\n",
        "            # `nn.GRU` takes a tensor as hidden state\n",
        "            return  torch.zeros((self.rnn.num_layers,\n",
        "                                 batch_size, self.num_hiddens),\n",
        "                                 device=device)\n",
        "        else:\n",
        "            # `nn.LSTM` takes a tuple of hidden states\n",
        "            return (torch.zeros((\n",
        "                self.rnn.num_layers,\n",
        "                batch_size, self.num_hiddens), device=device),\n",
        "                    torch.zeros((\n",
        "                        self.rnn.num_layers,\n",
        "                        batch_size, self.num_hiddens), device=device))"
      ],
      "metadata": {
        "id": "upwsoDqLErBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(prefix, num_preds, net, vocab, device):\n",
        "    \"\"\"Generate new characters following the `prefix`.\"\"\"\n",
        "    state = net.begin_state(batch_size=1, device=device)\n",
        "    outputs = [vocab[prefix[0]]]\n",
        "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
        "    for y in prefix[1:]:  # Warm-up period\n",
        "        _, state = net(get_input(), state)\n",
        "        outputs.append(vocab[y])\n",
        "    for _ in range(num_preds):  # Predict `num_preds` steps\n",
        "        y, state = net(get_input(), state)\n",
        "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
        "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
      ],
      "metadata": {
        "id": "SRTF6RvNEtfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ],
      "metadata": {
        "id": "8Scx3CtNEx0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm"
      ],
      "metadata": {
        "id": "rV7n0KZkE75P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(net, train_iter, loss, optimizer, device):\n",
        "    \"\"\"Train a net within one epoch.\"\"\"\n",
        "    state = None\n",
        "    # Sum of training loss, no. of tokens\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "    for X, Y in train_iter:\n",
        "        if state is None:\n",
        "            # Initialize `state` when it is the first iteration\n",
        "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
        "        else:\n",
        "            if not isinstance(state, tuple):\n",
        "                # `state` is a tensor for `nn.GRU`\n",
        "                state.detach_()\n",
        "            else:\n",
        "                # `state` is a tuple of tensors for `nn.LSTM`\n",
        "                for s in state:\n",
        "                    s.detach_()\n",
        "        y = Y.T.reshape(-1)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_hat, state = net(X, state)\n",
        "        l = loss(y_hat, y.long()).mean()\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        grad_clipping(net, 1)\n",
        "        optimizer.step()\n",
        "        total_loss += float(l * y.numel())\n",
        "        total_tokens += y.numel()\n",
        "    return math.exp(total_loss / total_tokens)"
      ],
      "metadata": {
        "id": "m8isntl7E9Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, vocab, lr, num_epochs, device):\n",
        "    \"\"\"Train a model.\"\"\"\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    perplexities = []\n",
        "    # Initialize\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr)\n",
        "    # Train and predict\n",
        "    for epoch in range(num_epochs):\n",
        "        ppl = train_epoch(\n",
        "            net, train_iter, loss, optimizer, device)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(predict('philosophy', 30, net, vocab, device))\n",
        "            perplexities.append(ppl)\n",
        "    print(f'perplexity {ppl:.1f}, device {str(device)}')\n",
        "    print(predict('philosophy', 30, net, vocab, device))\n",
        "    return perplexities"
      ],
      "metadata": {
        "id": "Ki3bXpF-E-pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs, lr = 350, 3.5\n",
        "batch_size, num_steps = 32, 35\n",
        "\n",
        "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
        "\n",
        "num_hiddens = 30\n",
        "rnn_layer = nn.RNN(len(vocab), num_hiddens, 3)\n",
        "\n",
        "device = try_gpu()\n",
        "net = RNNModel(rnn_layer, vocab_size=len(vocab))\n",
        "net = net.to(device)\n",
        "\n",
        "perplexities = train(net, train_iter, vocab, lr, num_epochs, device) #1 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uup5A2F8FIB4",
        "outputId": "9fdce361-6d52-4475-a0a0-d3d19fc449ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophyt tt tt tt tt tt tt tt tt tt t\n",
            "philosophy                              \n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophyseiseiseiseiseiseiseiseiseisei\n",
            "philosophy ie ie ie ie ie ie ie ie ie ie\n",
            "philosophy tttt tttt tttt tttt tttt tttt\n",
            "philosophye esesresesresessesesse esesre\n",
            "philosophyininininininininininininininin\n",
            "philosophy                              \n",
            "philosophyoooooooooooooooooooooooooooooo\n",
            "philosophyrtrtrtrtrtrtrtrtrtrtrtrtrtrtrt\n",
            "philosophy                              \n",
            "philosophy                              \n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophytttttttttttttttttttttttttttttt\n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophyoooooooooooooooooooooooooooooo\n",
            "philosophyrlrlrlrlrlrlrlrlrlrlrlrlrlrlrl\n",
            "philosophyaoaoaoaoaoaoaoaoaoaoaoaoaoaoao\n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophyoooooooooooooooooooooooooooooo\n",
            "philosophy                              \n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophyssssssssssssssssssssssssssssss\n",
            "philosophysososososososososososososososo\n",
            "philosophytttttttttttttttttttttttttttttt\n",
            "philosophyssssssssssssssssssssssssssssss\n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophynnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
            "philosophytttttttttttttttttttttttttttttt\n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophyoaoaoaoaoaoaoaoaoaoaoaoaoaoaoa\n",
            "philosophyeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "philosophye e e e e e e e e e e e e e e \n",
            "perplexity 524.6, device cpu\n",
            "philosophye e e e e e e e e e e e e e e \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_perplexity(perplexities):\n",
        "    epochs = range(10, len(perplexities * 10) + 1, 10)\n",
        "    plt.plot(epochs, perplexities, 'b', label='Train perplexity')\n",
        "    plt.title('Training perplexity')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Perplexity')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_perplexity(perplexities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0Df6eHstFd0R",
        "outputId": "67133741-58ae-4060-8fd1-12e913051de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 5\n",
        "\n",
        "def synthetic_data(w, b, num_examples):\n",
        "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
        "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
        "    y = torch.sinh(X) @ w + b\n",
        "    e = torch.normal(0, 0.06, y.shape)\n",
        "    y += e\n",
        "    return X, y.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "NMHYJnjfF7ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_w = torch.tensor([-3.])\n",
        "X = torch.normal(0, 1, (1, len(true_w)))\n",
        "true_b = torch.cosh(X)\n",
        "features, labels = synthetic_data(true_w, true_b, 150)"
      ],
      "metadata": {
        "id": "s1BHHLNjGvvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_iter(batch_size, features, labels):\n",
        "    num_examples = len(features)\n",
        "    indices = list(range(num_examples))\n",
        "    # The examples are read at random, in no particular order\n",
        "    np.random.shuffle(indices)\n",
        "    for i in range(0, num_examples, batch_size):\n",
        "        batch_indices = torch.tensor(\n",
        "            indices[i: min(i + batch_size, num_examples)])\n",
        "        yield features[batch_indices], labels[batch_indices]"
      ],
      "metadata": {
        "id": "rAPOYoh4HRCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ],
      "metadata": {
        "id": "5OvggWwrHRW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ],
      "metadata": {
        "id": "kYLoKjkYHVlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Did not find Nadaraya kernel"
      ],
      "metadata": {
        "id": "WyPHp6gxIrJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAZZ9tuFI1T9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}